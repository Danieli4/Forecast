{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# multivariate output 1d cnn example\n",
    "import tf as tf\n",
    "from numpy import array\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, LSTM, LeakyReLU\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D, Conv2D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# split a multivariate sequence into samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      number1  2-number  3-number  4-number  5-number  6-number\n0        15.0      17.0      22.0      23.0      25.0      33.0\n1        23.0      29.0      44.0      19.0      24.0      45.0\n2        38.0       7.0       3.0      45.0      26.0       4.0\n3        31.0      26.0      44.0      37.0      40.0      27.0\n4        16.0      17.0      12.0      21.0      23.0      35.0\n...       ...       ...       ...       ...       ...       ...\n5424     18.0       7.0      16.0      23.0      37.0      43.0\n5425     15.0      13.0      35.0      33.0      34.0      28.0\n5426     27.0      44.0      40.0      29.0      41.0      25.0\n5427      1.0      10.0      33.0      37.0      40.0      44.0\n5428     24.0      33.0      45.0      37.0      38.0       5.0\n\n[5429 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number1</th>\n      <th>2-number</th>\n      <th>3-number</th>\n      <th>4-number</th>\n      <th>5-number</th>\n      <th>6-number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15.0</td>\n      <td>17.0</td>\n      <td>22.0</td>\n      <td>23.0</td>\n      <td>25.0</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>23.0</td>\n      <td>29.0</td>\n      <td>44.0</td>\n      <td>19.0</td>\n      <td>24.0</td>\n      <td>45.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>45.0</td>\n      <td>26.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>31.0</td>\n      <td>26.0</td>\n      <td>44.0</td>\n      <td>37.0</td>\n      <td>40.0</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16.0</td>\n      <td>17.0</td>\n      <td>12.0</td>\n      <td>21.0</td>\n      <td>23.0</td>\n      <td>35.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5424</th>\n      <td>18.0</td>\n      <td>7.0</td>\n      <td>16.0</td>\n      <td>23.0</td>\n      <td>37.0</td>\n      <td>43.0</td>\n    </tr>\n    <tr>\n      <th>5425</th>\n      <td>15.0</td>\n      <td>13.0</td>\n      <td>35.0</td>\n      <td>33.0</td>\n      <td>34.0</td>\n      <td>28.0</td>\n    </tr>\n    <tr>\n      <th>5426</th>\n      <td>27.0</td>\n      <td>44.0</td>\n      <td>40.0</td>\n      <td>29.0</td>\n      <td>41.0</td>\n      <td>25.0</td>\n    </tr>\n    <tr>\n      <th>5427</th>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>33.0</td>\n      <td>37.0</td>\n      <td>40.0</td>\n      <td>44.0</td>\n    </tr>\n    <tr>\n      <th>5428</th>\n      <td>24.0</td>\n      <td>33.0</td>\n      <td>45.0</td>\n      <td>37.0</td>\n      <td>38.0</td>\n      <td>5.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5429 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем датафрейм\n",
    "frame = pd.read_csv('Gosloto_6x45.csv', header=0, sep=';')\n",
    "frame\n",
    "\n",
    "# удвляем дату и тираж\n",
    "frame = frame.drop(columns=['datetime', 'tiraz'], axis=1).astype(float)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "in_seq1 = frame[\"number1\"].to_numpy()\n",
    "in_seq2 = frame[\"2-number\"].to_numpy()\n",
    "in_seq3 = frame[\"3-number\"].to_numpy()\n",
    "in_seq4 = frame[\"4-number\"].to_numpy()\n",
    "in_seq5 = frame[\"5-number\"].to_numpy()\n",
    "in_seq6 = frame[\"6-number\"].to_numpy()\n",
    "\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "in_seq4 = in_seq4.reshape((len(in_seq4), 1))\n",
    "in_seq5 = in_seq5.reshape((len(in_seq5), 1))\n",
    "in_seq6 = in_seq6.reshape((len(in_seq6), 1))\n",
    "# horizontally stack columns\n",
    "dataset_new = hstack((in_seq1, in_seq2, in_seq3, in_seq4, in_seq5, in_seq6))\n",
    "#dataset= np.array(range(0,54,1)).reshape(9,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "validat_x = dataset_new[-401:-1]\n",
    "validat_y = dataset_new[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# нужно вычесть 5429+validat_x[!это!:]\n",
    "dataset = dataset_new[:5028]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_input = 400\n",
    "generator = TimeseriesGenerator(dataset, dataset, length=n_input, batch_size=80)\n",
    "\n",
    "#np.delete(validat)\n",
    "\n",
    "# for i in range(len(generator)):\n",
    "# \tx_g, y_g = generator[i]\n",
    "# \tprint('%s => %s' % (x_g, y_g))\n",
    "# generator.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5028\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tprint(len(sequences))\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif end_ix > len(sequences)-1:\n",
    "\t\t\tprint('!')\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "# choose a number of time steps\n",
    "n_steps = 6\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8. 33. 32. 30. 31. 44.]\n",
      "  [25. 19. 29. 31. 33. 26.]\n",
      "  [40. 16. 26. 23. 27. 30.]\n",
      "  ...\n",
      "  [15. 13. 35. 33. 34. 28.]\n",
      "  [27. 44. 40. 29. 41. 25.]\n",
      "  [ 1. 10. 33. 37. 40. 44.]]]\n",
      "[[24. 33. 45. 37. 38.  5.]]\n",
      "[[[36 37 38 39 40 41]\n",
      "  [42 43 44 45 46 47]\n",
      "  [48 49 50 51 52 53]]]\n",
      "[[54 55 56 57 58 59]]\n"
     ]
    }
   ],
   "source": [
    "x_val1 = array([[[36 ,37, 38, 39, 40, 41], [42, 43, 44, 45, 46, 47], [48, 49, 50, 51, 52, 53]]])\n",
    "y_val1 = array( [[54, 55, 56, 57, 58, 59]])\n",
    "\n",
    "x_val = array([validat_x])\n",
    "y_val = array( validat_y)\n",
    "print (x_val)\n",
    "print (y_val)\n",
    "print (x_val1)\n",
    "print (y_val1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "58/58 - 98s - loss: 1286860.7500 - val_loss: 172.7437\n",
      "Epoch 2/150\n",
      "58/58 - 104s - loss: 173.2757 - val_loss: 174.8228\n",
      "Epoch 3/150\n",
      "58/58 - 105s - loss: 172.7532 - val_loss: 170.8277\n",
      "Epoch 4/150\n",
      "58/58 - 106s - loss: 172.5882 - val_loss: 169.3786\n",
      "Epoch 5/150\n",
      "58/58 - 110s - loss: 174.3152 - val_loss: 172.0888\n",
      "Epoch 6/150\n",
      "58/58 - 104s - loss: 173.2493 - val_loss: 171.0731\n",
      "Epoch 7/150\n",
      "58/58 - 104s - loss: 171.1056 - val_loss: 175.7711\n",
      "Epoch 8/150\n",
      "58/58 - 100s - loss: 178.4313 - val_loss: 173.9443\n",
      "Epoch 9/150\n",
      "58/58 - 104s - loss: 170.0593 - val_loss: 165.3134\n",
      "Epoch 10/150\n",
      "58/58 - 100s - loss: 170.7309 - val_loss: 165.3538\n",
      "Epoch 11/150\n",
      "58/58 - 100s - loss: 172.1399 - val_loss: 167.7204\n",
      "Epoch 12/150\n",
      "58/58 - 101s - loss: 171.5206 - val_loss: 164.5005\n",
      "Epoch 13/150\n",
      "58/58 - 104s - loss: 170.2172 - val_loss: 178.3883\n",
      "Epoch 14/150\n",
      "58/58 - 115s - loss: 169.3319 - val_loss: 163.6149\n",
      "Epoch 15/150\n",
      "58/58 - 107s - loss: 165.1428 - val_loss: 162.2894\n",
      "Epoch 16/150\n",
      "58/58 - 114s - loss: 165.7325 - val_loss: 162.0208\n",
      "Epoch 17/150\n",
      "58/58 - 119s - loss: 164.1634 - val_loss: 159.7526\n",
      "Epoch 18/150\n",
      "58/58 - 115s - loss: 166.7325 - val_loss: 164.7833\n",
      "Epoch 19/150\n",
      "58/58 - 112s - loss: 167.5362 - val_loss: 162.9816\n",
      "Epoch 20/150\n",
      "58/58 - 113s - loss: 168.1652 - val_loss: 157.8978\n",
      "Epoch 21/150\n",
      "58/58 - 111s - loss: 164.3772 - val_loss: 157.3675\n",
      "Epoch 22/150\n",
      "58/58 - 111s - loss: 164.6777 - val_loss: 162.8693\n",
      "Epoch 23/150\n",
      "58/58 - 111s - loss: 162.9796 - val_loss: 158.7706\n",
      "Epoch 24/150\n",
      "58/58 - 111s - loss: 163.4261 - val_loss: 160.7217\n",
      "Epoch 25/150\n",
      "58/58 - 112s - loss: 167.3143 - val_loss: 160.7377\n",
      "Epoch 26/150\n",
      "58/58 - 112s - loss: 168.5130 - val_loss: 160.7584\n",
      "Epoch 27/150\n",
      "58/58 - 113s - loss: 177.2649 - val_loss: 172.4689\n",
      "Epoch 28/150\n",
      "58/58 - 111s - loss: 163.2677 - val_loss: 167.8812\n",
      "Epoch 29/150\n",
      "58/58 - 112s - loss: 162.1944 - val_loss: 156.4673\n",
      "Epoch 30/150\n",
      "58/58 - 110s - loss: 162.0053 - val_loss: 173.0054\n",
      "Epoch 31/150\n",
      "58/58 - 108s - loss: 161.5373 - val_loss: 156.0283\n",
      "Epoch 32/150\n",
      "58/58 - 110s - loss: 169.3641 - val_loss: 172.7756\n",
      "Epoch 33/150\n",
      "58/58 - 109s - loss: 159.6970 - val_loss: 158.4162\n",
      "Epoch 34/150\n",
      "58/58 - 108s - loss: 162.1150 - val_loss: 163.1326\n",
      "Epoch 35/150\n",
      "58/58 - 108s - loss: 166.8345 - val_loss: 167.3595\n",
      "Epoch 36/150\n",
      "58/58 - 111s - loss: 162.2861 - val_loss: 161.4079\n",
      "Epoch 37/150\n",
      "58/58 - 108s - loss: 160.6983 - val_loss: 179.0265\n",
      "Epoch 38/150\n",
      "58/58 - 107s - loss: 168.3045 - val_loss: 161.5456\n",
      "Epoch 39/150\n",
      "58/58 - 107s - loss: 165.8994 - val_loss: 155.8975\n",
      "Epoch 40/150\n",
      "58/58 - 106s - loss: 161.5627 - val_loss: 156.4033\n",
      "Epoch 41/150\n",
      "58/58 - 107s - loss: 160.0058 - val_loss: 165.5676\n",
      "Epoch 42/150\n",
      "58/58 - 107s - loss: 160.6916 - val_loss: 154.1717\n",
      "Epoch 43/150\n",
      "58/58 - 107s - loss: 164.2264 - val_loss: 173.9088\n",
      "Epoch 44/150\n",
      "58/58 - 107s - loss: 163.1077 - val_loss: 170.0882\n",
      "Epoch 45/150\n",
      "58/58 - 106s - loss: 164.5545 - val_loss: 154.5078\n",
      "Epoch 46/150\n",
      "58/58 - 107s - loss: 159.6069 - val_loss: 176.4313\n",
      "Epoch 47/150\n",
      "58/58 - 107s - loss: 160.0499 - val_loss: 157.1967\n",
      "Epoch 48/150\n",
      "58/58 - 107s - loss: 163.5904 - val_loss: 157.8674\n",
      "Epoch 49/150\n",
      "58/58 - 107s - loss: 162.9033 - val_loss: 155.8773\n",
      "Epoch 50/150\n",
      "58/58 - 107s - loss: 160.3699 - val_loss: 158.6520\n",
      "Epoch 51/150\n",
      "58/58 - 107s - loss: 167.7986 - val_loss: 159.4322\n",
      "Epoch 52/150\n",
      "58/58 - 108s - loss: 160.1751 - val_loss: 188.3983\n",
      "Epoch 53/150\n",
      "58/58 - 107s - loss: 173.0703 - val_loss: 182.9188\n",
      "Epoch 54/150\n",
      "58/58 - 106s - loss: 179.6577 - val_loss: 188.7670\n",
      "Epoch 55/150\n",
      "58/58 - 106s - loss: 159.0312 - val_loss: 152.9138\n",
      "Epoch 56/150\n",
      "58/58 - 106s - loss: 160.0624 - val_loss: 155.8268\n",
      "Epoch 57/150\n",
      "58/58 - 106s - loss: 160.3868 - val_loss: 163.4934\n",
      "Epoch 58/150\n",
      "58/58 - 107s - loss: 161.8280 - val_loss: 163.6499\n",
      "Epoch 59/150\n",
      "58/58 - 106s - loss: 160.6293 - val_loss: 159.9634\n",
      "Epoch 60/150\n",
      "58/58 - 106s - loss: 161.1576 - val_loss: 154.9330\n",
      "Epoch 61/150\n",
      "58/58 - 107s - loss: 158.9155 - val_loss: 157.1934\n",
      "Epoch 62/150\n",
      "58/58 - 106s - loss: 167.5798 - val_loss: 160.9097\n",
      "Epoch 63/150\n",
      "58/58 - 106s - loss: 169.6893 - val_loss: 155.0891\n",
      "Epoch 64/150\n",
      "58/58 - 107s - loss: 158.5952 - val_loss: 151.4592\n",
      "Epoch 65/150\n",
      "58/58 - 106s - loss: 160.0440 - val_loss: 157.3972\n",
      "Epoch 66/150\n",
      "58/58 - 107s - loss: 160.3514 - val_loss: 157.1796\n",
      "Epoch 67/150\n",
      "58/58 - 107s - loss: 158.5646 - val_loss: 153.9448\n",
      "Epoch 68/150\n",
      "58/58 - 106s - loss: 161.3388 - val_loss: 157.2464\n",
      "Epoch 69/150\n",
      "58/58 - 111s - loss: 159.1145 - val_loss: 157.4950\n",
      "Epoch 70/150\n",
      "58/58 - 106s - loss: 161.7296 - val_loss: 154.3140\n",
      "Epoch 71/150\n",
      "58/58 - 106s - loss: 158.6607 - val_loss: 156.1033\n",
      "Epoch 72/150\n",
      "58/58 - 106s - loss: 156.3422 - val_loss: 154.8188\n",
      "Epoch 73/150\n",
      "58/58 - 106s - loss: 158.4186 - val_loss: 170.9822\n",
      "Epoch 74/150\n",
      "58/58 - 106s - loss: 159.9031 - val_loss: 168.3921\n",
      "Epoch 75/150\n",
      "58/58 - 106s - loss: 157.8528 - val_loss: 162.9093\n",
      "Epoch 76/150\n",
      "58/58 - 106s - loss: 162.7407 - val_loss: 178.3643\n",
      "Epoch 77/150\n",
      "58/58 - 107s - loss: 158.1131 - val_loss: 154.0947\n",
      "Epoch 78/150\n",
      "58/58 - 107s - loss: 160.5367 - val_loss: 155.1536\n",
      "Epoch 79/150\n",
      "58/58 - 107s - loss: 158.3156 - val_loss: 151.0231\n",
      "Epoch 80/150\n",
      "58/58 - 107s - loss: 160.8374 - val_loss: 159.4773\n",
      "Epoch 81/150\n",
      "58/58 - 106s - loss: 158.6923 - val_loss: 150.3494\n",
      "Epoch 82/150\n",
      "58/58 - 106s - loss: 162.9960 - val_loss: 156.2008\n",
      "Epoch 83/150\n",
      "58/58 - 107s - loss: 160.2357 - val_loss: 156.7271\n",
      "Epoch 84/150\n",
      "58/58 - 107s - loss: 159.1302 - val_loss: 151.2504\n",
      "Epoch 85/150\n",
      "58/58 - 106s - loss: 157.5422 - val_loss: 150.4153\n",
      "Epoch 86/150\n",
      "58/58 - 106s - loss: 158.3500 - val_loss: 163.9186\n",
      "Epoch 87/150\n",
      "58/58 - 106s - loss: 163.6798 - val_loss: 152.4149\n",
      "Epoch 88/150\n",
      "58/58 - 106s - loss: 160.7995 - val_loss: 150.4786\n",
      "Epoch 89/150\n",
      "58/58 - 106s - loss: 160.1997 - val_loss: 166.6811\n",
      "Epoch 90/150\n",
      "58/58 - 105s - loss: 158.2569 - val_loss: 151.4583\n",
      "Epoch 91/150\n",
      "58/58 - 107s - loss: 168.5678 - val_loss: 152.9971\n",
      "Epoch 92/150\n",
      "58/58 - 106s - loss: 163.5659 - val_loss: 151.5412\n",
      "Epoch 93/150\n",
      "58/58 - 107s - loss: 161.0665 - val_loss: 151.4733\n",
      "Epoch 94/150\n",
      "58/58 - 109s - loss: 157.9560 - val_loss: 164.6853\n",
      "Epoch 95/150\n",
      "58/58 - 108s - loss: 164.9007 - val_loss: 178.9481\n",
      "Epoch 96/150\n",
      "58/58 - 109s - loss: 160.0373 - val_loss: 162.2428\n",
      "Epoch 97/150\n",
      "58/58 - 106s - loss: 157.5824 - val_loss: 151.1401\n",
      "Epoch 98/150\n",
      "58/58 - 107s - loss: 159.1671 - val_loss: 152.2465\n",
      "Epoch 99/150\n",
      "58/58 - 107s - loss: 160.2481 - val_loss: 157.8704\n",
      "Epoch 100/150\n",
      "58/58 - 103s - loss: 158.2973 - val_loss: 159.6837\n",
      "Epoch 101/150\n",
      "58/58 - 101s - loss: 156.9808 - val_loss: 150.0170\n",
      "Epoch 102/150\n",
      "58/58 - 101s - loss: 157.5522 - val_loss: 168.7859\n",
      "Epoch 103/150\n",
      "58/58 - 100s - loss: 166.7348 - val_loss: 150.7633\n",
      "Epoch 104/150\n",
      "58/58 - 98s - loss: 161.3383 - val_loss: 160.6317\n",
      "Epoch 105/150\n",
      "58/58 - 98s - loss: 167.9937 - val_loss: 164.5026\n",
      "Epoch 106/150\n",
      "58/58 - 100s - loss: 166.0193 - val_loss: 164.5842\n",
      "Epoch 107/150\n",
      "58/58 - 102s - loss: 160.0830 - val_loss: 189.1245\n",
      "Epoch 108/150\n",
      "58/58 - 98s - loss: 164.3786 - val_loss: 150.0928\n",
      "Epoch 109/150\n",
      "58/58 - 98s - loss: 157.3440 - val_loss: 165.0000\n",
      "Epoch 110/150\n",
      "58/58 - 98s - loss: 168.5172 - val_loss: 154.4729\n",
      "Epoch 111/150\n",
      "58/58 - 98s - loss: 163.7161 - val_loss: 157.1641\n",
      "Epoch 112/150\n",
      "58/58 - 99s - loss: 158.6863 - val_loss: 149.7894\n",
      "Epoch 113/150\n",
      "58/58 - 98s - loss: 156.5752 - val_loss: 161.7697\n",
      "Epoch 114/150\n",
      "58/58 - 99s - loss: 161.4471 - val_loss: 155.5237\n",
      "Epoch 115/150\n",
      "58/58 - 98s - loss: 161.6886 - val_loss: 153.3152\n",
      "Epoch 116/150\n",
      "58/58 - 98s - loss: 159.3512 - val_loss: 152.8723\n",
      "Epoch 117/150\n",
      "58/58 - 98s - loss: 158.2714 - val_loss: 153.6218\n",
      "Epoch 118/150\n",
      "58/58 - 99s - loss: 162.8650 - val_loss: 156.0426\n",
      "Epoch 119/150\n",
      "58/58 - 99s - loss: 160.8193 - val_loss: 158.8902\n",
      "Epoch 120/150\n",
      "58/58 - 98s - loss: 162.3402 - val_loss: 152.5777\n",
      "Epoch 121/150\n",
      "58/58 - 98s - loss: 161.1088 - val_loss: 154.3274\n",
      "Epoch 122/150\n",
      "58/58 - 97s - loss: 158.3057 - val_loss: 159.1215\n",
      "Epoch 123/150\n",
      "58/58 - 98s - loss: 159.4302 - val_loss: 155.5418\n",
      "Epoch 124/150\n",
      "58/58 - 97s - loss: 161.5646 - val_loss: 179.6760\n",
      "Epoch 125/150\n",
      "58/58 - 99s - loss: 161.4688 - val_loss: 158.9681\n",
      "Epoch 126/150\n",
      "58/58 - 99s - loss: 166.9013 - val_loss: 158.7155\n",
      "Epoch 127/150\n",
      "58/58 - 97s - loss: 157.5820 - val_loss: 178.9320\n",
      "Epoch 128/150\n",
      "58/58 - 97s - loss: 164.0118 - val_loss: 172.9013\n",
      "Epoch 129/150\n",
      "58/58 - 97s - loss: 159.2090 - val_loss: 151.1321\n",
      "Epoch 130/150\n",
      "58/58 - 99s - loss: 162.1857 - val_loss: 151.2651\n",
      "Epoch 131/150\n",
      "58/58 - 98s - loss: 156.7724 - val_loss: 151.0906\n",
      "Epoch 132/150\n",
      "58/58 - 98s - loss: 158.2909 - val_loss: 153.3650\n",
      "Epoch 133/150\n",
      "58/58 - 98s - loss: 161.2811 - val_loss: 176.0426\n",
      "Epoch 134/150\n",
      "58/58 - 98s - loss: 162.0434 - val_loss: 164.4446\n",
      "Epoch 135/150\n",
      "58/58 - 98s - loss: 160.4742 - val_loss: 154.2916\n",
      "Epoch 136/150\n",
      "58/58 - 97s - loss: 158.5684 - val_loss: 149.8418\n",
      "Epoch 137/150\n",
      "58/58 - 98s - loss: 160.2071 - val_loss: 154.0328\n",
      "Epoch 138/150\n",
      "58/58 - 98s - loss: 164.9237 - val_loss: 166.0494\n",
      "Epoch 139/150\n",
      "58/58 - 101s - loss: 161.4018 - val_loss: 174.1666\n",
      "Epoch 140/150\n",
      "58/58 - 98s - loss: 156.9966 - val_loss: 152.2688\n",
      "Epoch 141/150\n",
      "58/58 - 97s - loss: 162.2723 - val_loss: 183.6866\n",
      "Epoch 142/150\n",
      "58/58 - 98s - loss: 158.9839 - val_loss: 152.8528\n",
      "Epoch 143/150\n",
      "58/58 - 98s - loss: 158.1355 - val_loss: 151.1236\n",
      "Epoch 144/150\n",
      "58/58 - 97s - loss: 156.5382 - val_loss: 151.4532\n",
      "Epoch 145/150\n",
      "58/58 - 98s - loss: 159.4730 - val_loss: 152.5902\n",
      "Epoch 146/150\n",
      "58/58 - 97s - loss: 155.1089 - val_loss: 150.0274\n",
      "Epoch 147/150\n",
      "58/58 - 97s - loss: 156.7931 - val_loss: 153.0086\n",
      "Epoch 148/150\n",
      "58/58 - 98s - loss: 161.3360 - val_loss: 164.8310\n",
      "Epoch 149/150\n",
      "58/58 - 98s - loss: 159.5041 - val_loss: 153.4084\n",
      "Epoch 150/150\n",
      "58/58 - 99s - loss: 157.5964 - val_loss: 153.4110\n",
      "Ok!\n"
     ]
    }
   ],
   "source": [
    "# the dataset knows the number of features, e.g. 2\n",
    "#n_features = X.shape[2]\n",
    "n_features = 6\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=1045, kernel_size=60, activation='relu', input_shape=(400, n_features)))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Conv1D(filters=64, kernel_size=45, activation='relu', input_shape=(395, 64)))\n",
    "#model.add(MaxPooling1D(pool_size=4))\n",
    "#model.add(LSTM(25))\n",
    "model.add(LeakyReLU())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='linear'))\n",
    "model.add(Dense(n_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "#model.fit(X, y, epochs=3, verbose=1)\n",
    "callbacks = [\n",
    "  # Остановить обучение если `val_loss` перестанет улучшаться в течение 2 эпох\n",
    "  tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "  # Записать логи TensorBoard в каталог `./logs` directory\n",
    "  tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "history = model.fit_generator(generator, epochs=150, verbose=2, validation_data=(generator))#, callbacks=callbacks)\n",
    "print(\"Ok!\")\n",
    "# demonstrate prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],\n",
    "         label='Средняя абсолютная ошибка на обучающем наборе')\n",
    "plt.plot(history.history['val_loss'],\n",
    "         label='Средняя абсолют  ная ошибка на проверочном наборе')\n",
    "plt.ylabel('Средняя ошибка')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27.77262  21.799314 17.548515 18.962217 30.750412 20.74894 ]]\n",
      "[[24. 33. 45. 37. 38.  5.]]\n",
      "[[[ 8. 33. 32. 30. 31. 44.]\n",
      "  [25. 19. 29. 31. 33. 26.]\n",
      "  [40. 16. 26. 23. 27. 30.]\n",
      "  ...\n",
      "  [15. 13. 35. 33. 34. 28.]\n",
      "  [27. 44. 40. 29. 41. 25.]\n",
      "  [ 1. 10. 33. 37. 40. 44.]]]\n",
      "[ 8. 33. 32. 30. 31. 44.]\n",
      "[24. 33. 45. 37. 38.  5.]\n",
      "[[ -3.77261925  11.2006855   27.45148468  18.03778267   7.24958801\n",
      "  -15.74893951]]\n"
     ]
    }
   ],
   "source": [
    "# x_input = array([[70,71,72,73,74,75], [76,77,78,79,80,81], [82,83,84,85,86,87]])\n",
    "# x_input = x_input.reshape((1, 3, n_features))\n",
    "x_input = array([dataset_new[-401:-1]])\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "print(y_val)\n",
    "print(x_input)\n",
    "print (dataset_new[-401])\n",
    "print (dataset_new[-1])\n",
    "print(y_val-yhat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Fedorov_A Сентябрьский курс. Шаблон для домашнего задания 7. Временные ряды. Прогнозирование акций Лукойла",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}